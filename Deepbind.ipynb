{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "uosH3ughmaVn"
   },
   "outputs": [],
   "source": [
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/content/drive')\n",
    "# After executing the cell above, Drive\n",
    "# files will be present in \"/content/drive/My Drive\".\n",
    "!ls \"/content/drive/My Drive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T15:07:20.606935Z",
     "start_time": "2021-05-31T15:07:20.497909Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "coXeS8RbmvD_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepfind  dream5  encode  rnac\tselex\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"/home/julian/Documents/bat/DeepBind_train/data\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T12:40:57.598540Z",
     "start_time": "2021-06-01T12:40:57.495684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T12:40:55.967483Z",
     "start_time": "2021-06-01T12:40:53.993414Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "UiSAAZ_OkWri"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "import math \n",
    "import random\n",
    "import gzip\n",
    "from scipy.stats import bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T12:41:07.326068Z",
     "start_time": "2021-06-01T12:41:07.323894Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "jASRrXw4kWrn"
   },
   "outputs": [],
   "source": [
    "nummotif=16 #number of motifs to discover\n",
    "bases='ACGT' #DNA bases\n",
    "basesRNA='ACGU'#RNA bases\n",
    "batch_size=64 #fixed batch size -> see notes to problem about it\n",
    "dictReverse={'A':'T','C':'G','G':'C','T':'A','N':'N'} #dictionary to implement reverse-complement mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T12:41:09.726728Z",
     "start_time": "2021-06-01T12:41:09.724519Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "iWEt7WVVkWrp"
   },
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    def __init__(self,filename,motiflen):\n",
    "        self.file=filename\n",
    "        self.motiflen=motiflen\n",
    "    \n",
    "    def getMotifLen(self):\n",
    "        return self.motiflen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T12:41:20.384069Z",
     "start_time": "2021-06-01T12:41:20.380294Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Jhp-yVajkWrs"
   },
   "outputs": [],
   "source": [
    "def seqtopad(sequence,motlen,kind='DNA'):\n",
    "    rows=len(sequence)+2*motlen-2\n",
    "    S=np.empty([rows,4])\n",
    "    base= bases if kind=='DNA' else basesRNA\n",
    "    for i in range(rows):\n",
    "        for j in range(4):\n",
    "            if i-motlen+1<len(sequence) and sequence[i-motlen+1]=='N' or i<motlen-1 or i>len(sequence)+motlen-2:\n",
    "                S[i,j]=np.float32(0.25)\n",
    "            elif sequence[i-motlen+1]==base[j]:\n",
    "                S[i,j]=np.float32(1)\n",
    "            else:\n",
    "                S[i,j]=np.float32(0)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T12:41:21.556510Z",
     "start_time": "2021-06-01T12:41:21.554166Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "qujC_-HAkWru"
   },
   "outputs": [],
   "source": [
    "def dinucshuffle(sequence):\n",
    "    b=[sequence[i:i+2] for i in range(0, len(sequence), 2)]\n",
    "    random.shuffle(b)\n",
    "    d=''.join([str(x) for x in b])\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T12:41:22.943707Z",
     "start_time": "2021-06-01T12:41:22.941286Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ju_lj4g8kWrw"
   },
   "outputs": [],
   "source": [
    "def logsampler(a,b):\n",
    "    x=tf.Variable(tf.random_uniform([],minval=0,maxval=1), trainable=False)\n",
    "    y=10**((math.log10(b)-math.log10(a))*x + math.log10(a))\n",
    "    \n",
    "#     x=np.random.uniform(low=0,high=1)\n",
    "#     y=10**((math.log10(b)-math.log10(a))*x + math.log10(a))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T12:41:24.171140Z",
     "start_time": "2021-06-01T12:41:24.168923Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "MFBv7OV-kWrz"
   },
   "outputs": [],
   "source": [
    "def sqrtsampler(a,b):\n",
    "    x=tf.Variable(tf.random_uniform([],minval=0,maxval=1), trainable=False)\n",
    "#     x=np.random.uniform(low=0,high=1)\n",
    "    y=(b-a)*(x**0.5)+a\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T12:41:25.652610Z",
     "start_time": "2021-06-01T12:41:25.648765Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "5NkULJwDkWr1"
   },
   "outputs": [],
   "source": [
    "class Chip(Experiment):\n",
    "    def __init__(self,filename,motiflen=24):\n",
    "        self.file = filename\n",
    "        self.motiflen = motiflen\n",
    "            \n",
    "    def openFile(self):\n",
    "        train_dataset=[]\n",
    "     \n",
    "        with gzip.open(self.file, 'rt') as data:\n",
    "            next(data)\n",
    "            reader = csv.reader(data,delimiter='\\t')\n",
    "            \n",
    "            for row in reader:\n",
    "                    train_dataset.append([seqtopad(row[2],self.motiflen),[1]])\n",
    "                    \n",
    "                    train_dataset.append([seqtopad(dinucshuffle(row[2]),self.motiflen),[0]])\n",
    "                   \n",
    "        \n",
    "        \n",
    "        random.shuffle(train_dataset)\n",
    "        frac1=int(len(train_dataset)*1/3)\n",
    "        frac2=int(len(train_dataset)*2/3)\n",
    "        return train_dataset[:frac1],train_dataset[frac1:frac2],train_dataset[frac2:],train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T12:41:27.609542Z",
     "start_time": "2021-06-01T12:41:27.607943Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "a48AQrhKkWr3"
   },
   "outputs": [],
   "source": [
    "filename='/home/julian/Documents/bat/DeepBind_train/data/encode/ELK1_GM12878_ELK1_(1277-1)_Stanford_AC.seq.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T12:41:37.684824Z",
     "start_time": "2021-06-01T12:41:30.474707Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tByxbfE2kWr6"
   },
   "outputs": [],
   "source": [
    "test= Chip(filename)\n",
    "d1,d2,d3,dataAll =test.openFile()\n",
    "\n",
    "data1=np.asarray([el[0] for el in d1],dtype=np.float32)\n",
    "label1=np.asarray([el[1] for el in d1],dtype=np.float32).reshape(len(data1),1)\n",
    "\n",
    "data2=np.asarray([el[0] for el in d2],dtype=np.float32)\n",
    "label2=np.asarray([el[1] for el in d2],dtype=np.float32).reshape(len(data2),1)\n",
    "\n",
    "data3=np.asarray([el[0] for el in d3],dtype=np.float32)\n",
    "label3=np.asarray([el[1] for el in d3],dtype=np.float32).reshape(len(data3),1)\n",
    "\n",
    "data=[data1,data2,data3]\n",
    "label=[label1,label2,label3]\n",
    "\n",
    "data_all=np.asarray([el[0] for el in dataAll],dtype=np.float32)\n",
    "label_all=np.asarray([el[1] for el in dataAll],dtype=np.float32).reshape(len(data_all),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T12:44:33.791615Z",
     "start_time": "2021-06-01T12:44:33.785611Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8Jx0FGiJkWr8"
   },
   "outputs": [],
   "source": [
    "def convolution(input_data, num_input_channels, num_filters, filter_shape, conv_weights,bias_weights,wd1,bd1,W,b,pooling,neuType,training,dropprob):\n",
    "\n",
    "    \n",
    "    # setup the convolutional layer operation\n",
    "    out_layer = tf.nn.conv1d(input_data, conv_weights, 1, padding='VALID')\n",
    "\n",
    "    out_layer= tf.subtract(out_layer,conv_bias)\n",
    "\n",
    "    # apply a ReLU non-linear activation\n",
    "    out_layer = tf.nn.relu(out_layer)\n",
    "\n",
    "    # now perform pooling\n",
    "    if pooling == 'max_pool':\n",
    "        pool=tf.reduce_max(out_layer,axis=1) \n",
    "        \n",
    "    elif pooling == 'avg_pool':\n",
    "        out_layer1= tf.reduce_max(out_layer, axis=1)\n",
    "        out_layer2= tf.reduce_mean(out_layer, axis=1)\n",
    "        \n",
    "        x_expanded = tf.expand_dims(out_layer1, 2)                 \n",
    "        y_expanded = tf.expand_dims(out_layer2, 2)  \n",
    "        \n",
    "        concatted = tf.concat([x_expanded, y_expanded], 2)  \n",
    "\n",
    "        pool = tf.reshape(concatted, [-1, 2*num_filters]) \n",
    "        \n",
    "\n",
    "    t =tf.constant(1 ,dtype=tf.float32)\n",
    "    \n",
    "    def ifTrain(pool):\n",
    "        pooldrop = tf.nn.dropout(pool,keep_prob=dropprob)\n",
    "#         pooldrop=tf.multiply(pool,mask) \n",
    "        out = tf.matmul(pooldrop, wd1) + bd1\n",
    "        \n",
    "        return out\n",
    "    def ifTest(pool):\n",
    "        out = dropprob*tf.matmul(pool, wd1) + bd1\n",
    "        return out\n",
    "    \n",
    "    #check if there's hidden stage\n",
    "    if(neuType=='nohidden'):\n",
    "\n",
    "        out = tf.cond(tf.equal(training,t), lambda: ifTrain(pool), lambda: ifTest(pool))\n",
    "\n",
    "        \n",
    "    elif(neuType=='hidden'):\n",
    "\n",
    "\n",
    "        dense_layer1 = tf.matmul(pool, W) + b\n",
    "        dense_layer1=tf.nn.relu(dense_layer1)\n",
    "        \n",
    "        out = tf.cond(tf.equal(training,t), lambda: ifTrain(dense_layer1), lambda: ifTest(dense_layer1))\n",
    "        \n",
    "\n",
    "    return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T12:47:27.299820Z",
     "start_time": "2021-06-01T12:47:26.977702Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "_6AXbP8EkWsA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/julian/.virtualenvs/tensorflow/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From <ipython-input-13-04fad9542175>:39: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_initializable_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n",
      "WARNING:tensorflow:From /home/julian/.virtualenvs/tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:2881: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/julian/.virtualenvs/tensorflow/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "graph=tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    num_input_channels=4\n",
    "    num_filters=16\n",
    "    filter_shape=24\n",
    "    pooling='avg_pool'\n",
    "    neuType='nohidden'\n",
    "    \n",
    "    beta1=tf.placeholder_with_default(logsampler(10**-15,10**-3),shape=())\n",
    "    beta2=tf.placeholder_with_default(logsampler(10**-10,10**-3),shape=())\n",
    "    beta3=tf.placeholder_with_default(logsampler(10**-10,10**-3),shape=())\n",
    "\n",
    "    \n",
    "    \n",
    "    learning_rate= tf.placeholder_with_default(logsampler(0.0005, 0.05),shape=())\n",
    "    momentum_rate= tf.placeholder_with_default(sqrtsampler(0.95, 0.99),shape=())\n",
    "    \n",
    "\n",
    "    batch_size=64\n",
    "    with tf.device('/gpu:0'):\n",
    "    \n",
    "      x = tf.placeholder(tf.float32, [None, 147, 4])\n",
    "      y = tf.placeholder(tf.float32,[None,1])\n",
    "      dropprob = tf.placeholder_with_default(1.0, shape=())\n",
    "\n",
    "      # Distinguish training and testing: training=1 for training , =0 for testing\n",
    "      training = tf.placeholder_with_default(0.0, shape=())\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "      \n",
    "      #Set up iterator for the data\n",
    "      dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "      dataset = dataset.shuffle(500).repeat().batch(batch_size)\n",
    "      \n",
    "                  \n",
    "      iterator = dataset.make_initializable_iterator()\n",
    "      data_X, data_y = iterator.get_next()      \n",
    "      data_y = tf.cast(data_y, tf.float32)\n",
    "      \n",
    "      \n",
    "   \n",
    "    with tf.device('/gpu:0'):\n",
    "      \n",
    "      conv_filt_shape = [filter_shape, num_input_channels, num_filters]\n",
    "\n",
    "      stdConv=tf.placeholder_with_default(logsampler(10**-7,10**-3),shape=()) \n",
    "      # initialise weights and bias for the filter\n",
    "      conv_weights = tf.Variable(tf.truncated_normal(conv_filt_shape, mean=0,stddev=stdConv), name='Conv1_W')\n",
    "      conv_bias = tf.Variable(tf.truncated_normal([num_filters]), name='Conv1_b')\n",
    "\n",
    "\n",
    "\n",
    "      if pooling=='max_pool':\n",
    "          W = tf.Variable(tf.truncated_normal([16,32], mean=0, stddev=0.3), name='W')\n",
    "          b = tf.Variable(tf.truncated_normal([32], mean=0, stddev=0.3), name='b')\n",
    "      else:\n",
    "          W = tf.Variable(tf.truncated_normal([32,32], mean=0, stddev=0.3), name='W')\n",
    "          b = tf.Variable(tf.truncated_normal([32], mean=0, stddev=0.3), name='b')     \n",
    "\n",
    "      if neuType == 'nohidden':\n",
    "          if pooling=='max_pool':\n",
    "              wdim1=16\n",
    "          else:\n",
    "              wdim1=32\n",
    "      else:\n",
    "          wdim1=32\n",
    "          \n",
    "      stdNeu=tf.placeholder_with_default(logsampler(10**-5,10**-2) ,shape=()) \n",
    "      wd1 = tf.Variable(tf.truncated_normal([wdim1,1], mean=0, stddev=stdNeu), name='w2')\n",
    "      bd1 = tf.Variable(tf.truncated_normal([1], mean=0, stddev=stdNeu), name='b2')\n",
    "\n",
    "\n",
    "      xconv = convolution(data_X,num_input_channels,num_filters,filter_shape,conv_weights,conv_bias,wd1,bd1,W,b,pooling,neuType,training,dropprob)\n",
    "\n",
    "\n",
    "      sig = tf.nn.sigmoid(xconv)\n",
    "      if neuType == 'hidden':\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=data_y,logits=xconv))+ beta1*tf.norm(conv_weights,ord=1)+ beta2*tf.norm(wd1,ord=1)+ beta3*tf.norm(W,ord=1)\n",
    "      else:\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=data_y,logits=xconv))+ beta1*tf.norm(conv_weights,ord=1)+ beta2*tf.norm(wd1,ord=1)\n",
    "\n",
    "      optimizer=tf.train.MomentumOptimizer(learning_rate,momentum_rate,use_nesterov=True).minimize(loss)\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "      #Set up iterator for the validation data\n",
    "      dataset_val = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "      dataset_val = dataset_val.batch(tf.cast(tf.size(y),tf.int64))\n",
    "                  \n",
    "      iterator_val = dataset_val.make_initializable_iterator()\n",
    "      data_XV, data_yV = iterator_val.get_next()      \n",
    "      data_yV = tf.cast(data_yV, tf.float32)\n",
    "    with tf.device('/gpu:0'):\n",
    "      xconvV = convolution(data_XV,num_input_channels,num_filters,filter_shape,conv_weights,conv_bias,wd1,bd1,W,b,pooling,neuType,training,dropprob)\n",
    "\n",
    "      sigV = tf.nn.sigmoid(xconvV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T13:02:14.251812Z",
     "start_time": "2021-06-01T12:50:21.090782Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "yY9abt5qkWsB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1070, pci bus id: 0000:09:00.0, compute capability: 6.1\n",
      "\n",
      "AUC for the number of iterations 4000 is: 0.81661029321624\n",
      "AUC for the number of iterations 8000 is: 0.8195726855308763\n",
      "AUC for the number of iterations 12000 is: 0.8182541318860124\n",
      "AUC for the number of iterations 16000 is: 0.8205344356339643\n",
      "AUC for the number of iterations 20000 is: 0.817153595827436\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.8274704006096462\n",
      "AUC for the number of iterations 8000 is: 0.8220149667000328\n",
      "AUC for the number of iterations 12000 is: 0.8227394090361643\n",
      "AUC for the number of iterations 16000 is: 0.8278087639411613\n",
      "AUC for the number of iterations 20000 is: 0.8267405597849522\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.8031352596536466\n",
      "AUC for the number of iterations 8000 is: 0.7962712990061624\n",
      "AUC for the number of iterations 12000 is: 0.8060495582170515\n",
      "AUC for the number of iterations 16000 is: 0.8067462400414355\n",
      "AUC for the number of iterations 20000 is: 0.8042409353044864\n",
      "===== Fold Done =====\n",
      "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.81661029321624, 0.8195726855308763, 0.8182541318860124, 0.8205344356339643, 0.817153595827436], [0.8274704006096462, 0.8220149667000328, 0.8227394090361643, 0.8278087639411613, 0.8267405597849522], [0.8031352596536466, 0.7962712990061624, 0.8060495582170515, 0.8067462400414355, 0.8042409353044864]]\n",
      "The Average AUC for each Iteration Step of The Three Folds is: [0.8157386511598443, 0.8126196504123572, 0.8156810330464094, 0.8183631465388537, 0.8160450303056249]\n",
      "Best hyperparameters So far:\n",
      "Best Learning Rate 0.006999765\n",
      "Best Momentum Rate 0.97605973\n",
      "Best Learning Step 16000\n",
      "Best Sigma Conv 2.3842838e-07\n",
      "Best Sigma NN 0.0013259818\n",
      "Best Dropout Prob 0.5\n",
      "Best Beta 1 1.3150905e-13\n",
      "Best Beta 2 7.2976654e-05\n",
      "Best Beta 3 2.3573244e-07\n",
      "AUC for the number of iterations 4000 is: 0.8263294893512689\n",
      "AUC for the number of iterations 8000 is: 0.8193515335064472\n",
      "AUC for the number of iterations 12000 is: 0.8164711589898472\n",
      "AUC for the number of iterations 16000 is: 0.8146349006452762\n",
      "AUC for the number of iterations 20000 is: 0.8196578377670541\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.823607694970768\n",
      "AUC for the number of iterations 8000 is: 0.8268575850854041\n",
      "AUC for the number of iterations 12000 is: 0.8295303593582277\n",
      "AUC for the number of iterations 16000 is: 0.8275994419007695\n",
      "AUC for the number of iterations 20000 is: 0.8268844033834244\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.826336696248813\n",
      "AUC for the number of iterations 8000 is: 0.8181971969825654\n",
      "AUC for the number of iterations 12000 is: 0.8171990780060872\n",
      "AUC for the number of iterations 16000 is: 0.8143570060120353\n",
      "AUC for the number of iterations 20000 is: 0.8117053336971929\n",
      "===== Fold Done =====\n",
      "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.8263294893512689, 0.8193515335064472, 0.8164711589898472, 0.8146349006452762, 0.8196578377670541], [0.823607694970768, 0.8268575850854041, 0.8295303593582277, 0.8275994419007695, 0.8268844033834244], [0.826336696248813, 0.8181971969825654, 0.8171990780060872, 0.8143570060120353, 0.8117053336971929]]\n",
      "The Average AUC for each Iteration Step of The Three Folds is: [0.82542462685695, 0.8214687718581389, 0.8210668654513874, 0.8188637828526937, 0.8194158582825571]\n",
      "Best hyperparameters So far:\n",
      "Best Learning Rate 0.0043164603\n",
      "Best Momentum Rate 0.98736864\n",
      "Best Learning Step 4000\n",
      "Best Sigma Conv 0.00021173901\n",
      "Best Sigma NN 0.0054507847\n",
      "Best Dropout Prob 0.75\n",
      "Best Beta 1 1.9448713e-15\n",
      "Best Beta 2 2.1460615e-10\n",
      "Best Beta 3 3.260729e-05\n",
      "AUC for the number of iterations 4000 is: 0.8168199523008169\n",
      "AUC for the number of iterations 8000 is: 0.8234254324131551\n",
      "AUC for the number of iterations 12000 is: 0.815781060192357\n",
      "AUC for the number of iterations 16000 is: 0.8202946511161386\n",
      "AUC for the number of iterations 20000 is: 0.820461995285805\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.8159815462246454\n",
      "AUC for the number of iterations 8000 is: 0.8164069819523303\n",
      "AUC for the number of iterations 12000 is: 0.832542715976113\n",
      "AUC for the number of iterations 16000 is: 0.8356355274880589\n",
      "AUC for the number of iterations 20000 is: 0.8314170440384316\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.8212757892362571\n",
      "AUC for the number of iterations 8000 is: 0.7858297736367105\n",
      "AUC for the number of iterations 12000 is: 0.8121775040168415\n",
      "AUC for the number of iterations 16000 is: 0.8242558748917472\n",
      "AUC for the number of iterations 20000 is: 0.8113797049953636\n",
      "===== Fold Done =====\n",
      "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.8168199523008169, 0.8234254324131551, 0.815781060192357, 0.8202946511161386, 0.820461995285805], [0.8159815462246454, 0.8164069819523303, 0.832542715976113, 0.8356355274880589, 0.8314170440384316], [0.8212757892362571, 0.7858297736367105, 0.8121775040168415, 0.8242558748917472, 0.8113797049953636]]\n",
      "The Average AUC for each Iteration Step of The Three Folds is: [0.8180257625872399, 0.8085540626673987, 0.8201670933951037, 0.8267286844986482, 0.8210862481065334]\n",
      "Best hyperparameters So far:\n",
      "Best Learning Rate 0.009439803\n",
      "Best Momentum Rate 0.9790915\n",
      "Best Learning Step 16000\n",
      "Best Sigma Conv 0.00014642945\n",
      "Best Sigma NN 0.0007650946\n",
      "Best Dropout Prob 0.5\n",
      "Best Beta 1 0.00055750675\n",
      "Best Beta 2 2.3704052e-08\n",
      "Best Beta 3 5.040506e-06\n",
      "AUC for the number of iterations 4000 is: 0.7943178208828807\n",
      "AUC for the number of iterations 8000 is: 0.8214631000011143\n",
      "AUC for the number of iterations 12000 is: 0.8239595058453788\n",
      "AUC for the number of iterations 16000 is: 0.823910747918733\n",
      "AUC for the number of iterations 20000 is: 0.8260313694569204\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.8286509281569143\n",
      "AUC for the number of iterations 8000 is: 0.8290838521106697\n",
      "AUC for the number of iterations 12000 is: 0.8293774602305538\n",
      "AUC for the number of iterations 16000 is: 0.8279264858207827\n",
      "AUC for the number of iterations 20000 is: 0.8282131281489732\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.7471314739371729\n",
      "AUC for the number of iterations 8000 is: 0.7727833926925508\n",
      "AUC for the number of iterations 12000 is: 0.7688655799149573\n",
      "AUC for the number of iterations 16000 is: 0.7690239562477549\n",
      "AUC for the number of iterations 20000 is: 0.7689567768362604\n",
      "===== Fold Done =====\n",
      "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.7943178208828807, 0.8214631000011143, 0.8239595058453788, 0.823910747918733, 0.8260313694569204], [0.8286509281569143, 0.8290838521106697, 0.8293774602305538, 0.8279264858207827, 0.8282131281489732], [0.7471314739371729, 0.7727833926925508, 0.7688655799149573, 0.7690239562477549, 0.7689567768362604]]\n",
      "The Average AUC for each Iteration Step of The Three Folds is: [0.7900334076589893, 0.807776781601445, 0.8074008486636299, 0.8069537299957569, 0.8077337581473847]\n",
      "AUC for the number of iterations 4000 is: 0.7807310763521271\n",
      "AUC for the number of iterations 8000 is: 0.8274477872259804\n",
      "AUC for the number of iterations 12000 is: 0.8249663570306145\n",
      "AUC for the number of iterations 16000 is: 0.8228704627266548\n",
      "AUC for the number of iterations 20000 is: 0.819369643593487\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.7910180643875989\n",
      "AUC for the number of iterations 8000 is: 0.8315309347326215\n",
      "AUC for the number of iterations 12000 is: 0.8302130069441978\n",
      "AUC for the number of iterations 16000 is: 0.8269167943147995\n",
      "AUC for the number of iterations 20000 is: 0.8257085777455495\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.6946030915060162\n",
      "AUC for the number of iterations 8000 is: 0.82628030731274\n",
      "AUC for the number of iterations 12000 is: 0.831201112184744\n",
      "AUC for the number of iterations 16000 is: 0.8289090063573304\n",
      "AUC for the number of iterations 20000 is: 0.827958748360544\n",
      "===== Fold Done =====\n",
      "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.7807310763521271, 0.8274477872259804, 0.8249663570306145, 0.8228704627266548, 0.819369643593487], [0.7910180643875989, 0.8315309347326215, 0.8302130069441978, 0.8269167943147995, 0.8257085777455495], [0.6946030915060162, 0.82628030731274, 0.831201112184744, 0.8289090063573304, 0.827958748360544]]\n",
      "The Average AUC for each Iteration Step of The Three Folds is: [0.755450744081914, 0.8284196764237807, 0.8287934920531854, 0.8262320877995949, 0.8243456565665269]\n",
      "Best hyperparameters So far:\n",
      "Best Learning Rate 0.0005062311\n",
      "Best Momentum Rate 0.9856873\n",
      "Best Learning Step 12000\n",
      "Best Sigma Conv 0.0003667186\n",
      "Best Sigma NN 0.0001448399\n",
      "Best Dropout Prob 1.0\n",
      "Best Beta 1 3.2515804e-12\n",
      "Best Beta 2 6.5651044e-08\n",
      "Best Beta 3 0.00015338416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for the number of iterations 4000 is: 0.8247234380746471\n",
      "AUC for the number of iterations 8000 is: 0.8227335922611418\n",
      "AUC for the number of iterations 12000 is: 0.8315645234539558\n",
      "AUC for the number of iterations 16000 is: 0.830370476657491\n",
      "AUC for the number of iterations 20000 is: 0.830078451503973\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.814265001006557\n",
      "AUC for the number of iterations 8000 is: 0.8207125377981273\n",
      "AUC for the number of iterations 12000 is: 0.8222155815008076\n",
      "AUC for the number of iterations 16000 is: 0.8260244763988529\n",
      "AUC for the number of iterations 20000 is: 0.8286969023820918\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.80995901707819\n",
      "AUC for the number of iterations 8000 is: 0.8024613770595885\n",
      "AUC for the number of iterations 12000 is: 0.8035794095451849\n",
      "AUC for the number of iterations 16000 is: 0.8056062785251439\n",
      "AUC for the number of iterations 20000 is: 0.8087036670908601\n",
      "===== Fold Done =====\n",
      "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.8247234380746471, 0.8227335922611418, 0.8315645234539558, 0.830370476657491, 0.830078451503973], [0.814265001006557, 0.8207125377981273, 0.8222155815008076, 0.8260244763988529, 0.8286969023820918], [0.80995901707819, 0.8024613770595885, 0.8035794095451849, 0.8056062785251439, 0.8087036670908601]]\n",
      "The Average AUC for each Iteration Step of The Three Folds is: [0.8163158187197981, 0.8153025023729525, 0.8191198381666495, 0.8206670771938293, 0.8224930069923083]\n",
      "AUC for the number of iterations 4000 is: 0.8191039128932674\n",
      "AUC for the number of iterations 8000 is: 0.8211705524412396\n",
      "AUC for the number of iterations 12000 is: 0.8230707184968071\n",
      "AUC for the number of iterations 16000 is: 0.8238835827881733\n",
      "AUC for the number of iterations 20000 is: 0.8200097655161654\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.8339069662792991\n",
      "AUC for the number of iterations 8000 is: 0.8399184445108516\n",
      "AUC for the number of iterations 12000 is: 0.8351858856342388\n",
      "AUC for the number of iterations 16000 is: 0.8364500026818298\n",
      "AUC for the number of iterations 20000 is: 0.8363808671992711\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.8327740850373002\n",
      "AUC for the number of iterations 8000 is: 0.8238745534135495\n",
      "AUC for the number of iterations 12000 is: 0.8285095847268131\n",
      "AUC for the number of iterations 16000 is: 0.832017359438394\n",
      "AUC for the number of iterations 20000 is: 0.8328501404850285\n",
      "===== Fold Done =====\n",
      "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.8191039128932674, 0.8211705524412396, 0.8230707184968071, 0.8238835827881733, 0.8200097655161654], [0.8339069662792991, 0.8399184445108516, 0.8351858856342388, 0.8364500026818298, 0.8363808671992711], [0.8327740850373002, 0.8238745534135495, 0.8285095847268131, 0.832017359438394, 0.8328501404850285]]\n",
      "The Average AUC for each Iteration Step of The Three Folds is: [0.8285949880699555, 0.8283211834552135, 0.8289220629526196, 0.8307836483027992, 0.8297469244001551]\n",
      "Best hyperparameters So far:\n",
      "Best Learning Rate 0.0083273025\n",
      "Best Momentum Rate 0.9765913\n",
      "Best Learning Step 16000\n",
      "Best Sigma Conv 0.0003664224\n",
      "Best Sigma NN 0.00066427316\n",
      "Best Dropout Prob 0.75\n",
      "Best Beta 1 0.0001727656\n",
      "Best Beta 2 2.7272666e-08\n",
      "Best Beta 3 2.0100282e-05\n",
      "AUC for the number of iterations 4000 is: 0.799946923514137\n",
      "AUC for the number of iterations 8000 is: 0.802368625249362\n",
      "AUC for the number of iterations 12000 is: 0.7977994851162946\n",
      "AUC for the number of iterations 16000 is: 0.7983344292257799\n",
      "AUC for the number of iterations 20000 is: 0.8045585526975672\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.8237564146234257\n",
      "AUC for the number of iterations 8000 is: 0.8110647421577376\n",
      "AUC for the number of iterations 12000 is: 0.8204957275316647\n",
      "AUC for the number of iterations 16000 is: 0.823216043332797\n",
      "AUC for the number of iterations 20000 is: 0.8216905349519047\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.8194153024256989\n",
      "AUC for the number of iterations 8000 is: 0.8224514289374097\n",
      "AUC for the number of iterations 12000 is: 0.8271532915823153\n",
      "AUC for the number of iterations 16000 is: 0.8241389200613736\n",
      "AUC for the number of iterations 20000 is: 0.8244267820992278\n",
      "===== Fold Done =====\n",
      "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.799946923514137, 0.802368625249362, 0.7977994851162946, 0.7983344292257799, 0.8045585526975672], [0.8237564146234257, 0.8110647421577376, 0.8204957275316647, 0.823216043332797, 0.8216905349519047], [0.8194153024256989, 0.8224514289374097, 0.8271532915823153, 0.8241389200613736, 0.8244267820992278]]\n",
      "The Average AUC for each Iteration Step of The Three Folds is: [0.8143728801877539, 0.8119615987815031, 0.8151495014100916, 0.8152297975399835, 0.8168919565828999]\n",
      "AUC for the number of iterations 4000 is: 0.8325907036743974\n",
      "AUC for the number of iterations 8000 is: 0.8346165955265299\n",
      "AUC for the number of iterations 12000 is: 0.8313637452774465\n",
      "AUC for the number of iterations 16000 is: 0.829447558760267\n",
      "AUC for the number of iterations 20000 is: 0.8285864589486119\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.7828087047319319\n",
      "AUC for the number of iterations 8000 is: 0.8335652941967292\n",
      "AUC for the number of iterations 12000 is: 0.8369430065889424\n",
      "AUC for the number of iterations 16000 is: 0.8283245808160703\n",
      "AUC for the number of iterations 20000 is: 0.8301461353439394\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.8122384179909944\n",
      "AUC for the number of iterations 8000 is: 0.8130362170124724\n",
      "AUC for the number of iterations 12000 is: 0.8277178771027504\n",
      "AUC for the number of iterations 16000 is: 0.827293219682941\n",
      "AUC for the number of iterations 20000 is: 0.8249301055656576\n",
      "===== Fold Done =====\n",
      "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.8325907036743974, 0.8346165955265299, 0.8313637452774465, 0.829447558760267, 0.8285864589486119], [0.7828087047319319, 0.8335652941967292, 0.8369430065889424, 0.8283245808160703, 0.8301461353439394], [0.8122384179909944, 0.8130362170124724, 0.8277178771027504, 0.827293219682941, 0.8249301055656576]]\n",
      "The Average AUC for each Iteration Step of The Three Folds is: [0.809212608799108, 0.8270727022452439, 0.8320082096563798, 0.8283551197530926, 0.827887566619403]\n",
      "Best hyperparameters So far:\n",
      "Best Learning Rate 0.0021195512\n",
      "Best Momentum Rate 0.97251856\n",
      "Best Learning Step 12000\n",
      "Best Sigma Conv 3.4445404e-06\n",
      "Best Sigma NN 0.0024041876\n",
      "Best Dropout Prob 0.5\n",
      "Best Beta 1 3.30247e-09\n",
      "Best Beta 2 1.2224219e-10\n",
      "Best Beta 3 0.00020229003\n",
      "AUC for the number of iterations 4000 is: 0.5002948113207547\n",
      "AUC for the number of iterations 8000 is: 0.5\n",
      "AUC for the number of iterations 12000 is: 0.5\n",
      "AUC for the number of iterations 16000 is: 0.5\n",
      "AUC for the number of iterations 20000 is: 0.5\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.5\n",
      "AUC for the number of iterations 8000 is: 0.5\n",
      "AUC for the number of iterations 12000 is: 0.5\n",
      "AUC for the number of iterations 16000 is: 0.5\n",
      "AUC for the number of iterations 20000 is: 0.5\n",
      "===== Fold Done =====\n",
      "AUC for the number of iterations 4000 is: 0.6734410547654917\n",
      "AUC for the number of iterations 8000 is: 0.6721931884949863\n",
      "AUC for the number of iterations 12000 is: 0.6687905338988005\n",
      "AUC for the number of iterations 16000 is: 0.6662645184106395\n",
      "AUC for the number of iterations 20000 is: 0.6747110241066183\n",
      "===== Fold Done =====\n",
      "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.5002948113207547, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5], [0.6734410547654917, 0.6721931884949863, 0.6687905338988005, 0.6662645184106395, 0.6747110241066183]]\n",
      "The Average AUC for each Iteration Step of The Three Folds is: [0.5579119553620822, 0.5573977294983288, 0.5562635112996002, 0.5554215061368798, 0.5582370080355394]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "with tf.Session(graph=graph, config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    dropoutList=[0.5,0.75,1.0] #list of possible dropout values\n",
    "    best_AUC=0\n",
    "\n",
    "    for iter in range(10):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        beta_1=sess.run(beta1)\n",
    "        beta_2=sess.run(beta2)\n",
    "        beta_3=sess.run(beta3)\n",
    "        lea_r,mom_r,stdc,stdn=sess.run([learning_rate,momentum_rate,stdConv,stdNeu])\n",
    "                \n",
    "        \n",
    "        prob=random.choice(dropoutList)\n",
    "        \n",
    "        crossV=[0,1,2]\n",
    "    \n",
    "        CV_auc_list=[]\n",
    "        Avg_List=[]\n",
    "        for c in crossV:\n",
    "              sess.run(tf.global_variables_initializer())\n",
    "              sess.run(tf.local_variables_initializer())\n",
    "              sess.run([conv_weights,wd1,conv_bias,bd1], feed_dict={stdConv:stdc,stdNeu:stdn})\n",
    "              t=copy.copy(crossV)\n",
    "              t.remove(c)\n",
    "              traind=np.concatenate((data[t[0]], data[t[1]]), axis=0)\n",
    "              labeltrain=np.concatenate((label[t[0]], label[t[1]]), axis=0)\n",
    "\n",
    "              testd=data[c]\n",
    "              labeltest=label[c]\n",
    "\n",
    "\n",
    "\n",
    "              avg_cost=0\n",
    "              auc_list=[]\n",
    "              iterationSteps=0\n",
    "              sess.run(iterator.initializer, feed_dict = {x: traind, y: labeltrain})\n",
    "              try:\n",
    "\n",
    "                  while iterationSteps <=20000:\n",
    "                          iterationSteps+=1\n",
    "                      \n",
    "                          ### Training\n",
    "                          _,lss=sess.run([optimizer,loss], feed_dict= {training: 1, dropprob: prob, beta1:beta_1, \n",
    "                                                                       beta2: beta_2, beta3:beta_3, learning_rate:lea_r, momentum_rate:mom_r,stdConv:stdc,stdNeu:stdn})\n",
    "                         \n",
    "                          \n",
    "                          if iterationSteps % 4000==0:\n",
    "                                  ## Validation\n",
    "\n",
    "                                  sess.run(iterator_val.initializer, feed_dict = {x: testd, y: labeltest})\n",
    "\n",
    "                                  l,yl=sess.run([sigV, data_yV], feed_dict= {training: 0, dropprob: prob, beta1:beta_1, \n",
    "                                                                       beta2: beta_2, beta3:beta_3, learning_rate:lea_r, momentum_rate:mom_r,stdConv:stdc,stdNeu:stdn})\n",
    "                                  auc=metrics.roc_auc_score(yl, l)\n",
    "                                  print('AUC for the number of iterations',iterationSteps,'is:',auc)\n",
    "                                  auc_list.append(auc)\n",
    "\n",
    "\n",
    "              except tf.errors.OutOfRangeError:\n",
    "                  pass\n",
    "              print('===== Fold Done =====') \n",
    "              CV_auc_list.append(auc_list)\n",
    "              \n",
    "        print('The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps:' , CV_auc_list)\n",
    "        for i in range(len(auc_list)):\n",
    "                Avg_List.append(np.mean([CV_auc_list[j][i] for j in range(len(CV_auc_list))]))\n",
    "        print('The Average AUC for each Iteration Step of The Three Folds is:', Avg_List)\n",
    "        \n",
    "    \n",
    "        \n",
    "        maxlist=max(Avg_List)\n",
    "        if maxlist>best_AUC:\n",
    "          best_AUC=maxlist\n",
    "          \n",
    "          ind=Avg_List.index(maxlist)\n",
    "          \n",
    "          lr,mr,sc,sn,b1,b2,b3 = sess.run([learning_rate, momentum_rate,stdConv, stdNeu,beta1,beta2,beta3], feed_dict= {training: 0, dropprob: prob, beta1:beta_1, \n",
    "                                                                       beta2: beta_2, beta3:beta_3, learning_rate:lea_r, momentum_rate:mom_r,stdConv:stdc,stdNeu:stdn})\n",
    "          print( 'Best hyperparameters So far:')\n",
    "          print( 'Best Learning Rate', lr)\n",
    "          print( 'Best Momentum Rate', mr)\n",
    "          print( 'Best Learning Step', (ind+1)*4000)\n",
    "          print( 'Best Sigma Conv', sc)\n",
    "          print( 'Best Sigma NN', sn)\n",
    "          print( 'Best Dropout Prob', prob)\n",
    "          print( 'Best Beta 1', b1)\n",
    "          print( 'Best Beta 2', b2)\n",
    "          print( 'Best Beta 3', b3)\n",
    "          \n",
    "          save_LearningRate=lr\n",
    "          save_Momentum=mr\n",
    "          save_LearningStep=(ind+1)*4000\n",
    "          save_SigmaConv=sc\n",
    "          save_SigmaNeu=sn\n",
    "          save_Dropprob=prob\n",
    "          save_Beta1=b1\n",
    "          save_Beta2=b2\n",
    "          save_Beta3=b3\n",
    "          \n",
    "          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T13:05:07.738480Z",
     "start_time": "2021-06-01T13:05:07.544195Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "XZK-IaoTkYBK"
   },
   "outputs": [],
   "source": [
    "graph2=tf.Graph()\n",
    "with graph2.as_default():\n",
    "    \n",
    "    num_input_channels=4\n",
    "    num_filters=16\n",
    "    filter_shape=24\n",
    "    pooling='max_pool'\n",
    "    neuType='hidden'\n",
    "    \n",
    "    beta1=save_Beta1\n",
    "    beta2=save_Beta2\n",
    "    beta3=save_Beta3\n",
    "\n",
    "    \n",
    "    \n",
    "    learning_rate= save_LearningRate\n",
    "    momentum_rate= save_Momentum\n",
    "    batch_size=64\n",
    "    \n",
    "    \n",
    "    with tf.device('/gpu:0'):\n",
    "    \n",
    "      x = tf.placeholder(tf.float32, [None, 147, 4],name='X')\n",
    "      y = tf.placeholder(tf.float32,[None,1],name='y')\n",
    "\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "      \n",
    "      #Set up iterator for the data\n",
    "      dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "      dataset = dataset.shuffle(500).repeat().batch(batch_size)\n",
    "      iterator = dataset.make_initializable_iterator()\n",
    "      data_X, data_y = iterator.get_next()\n",
    "      data_y = tf.cast(data_y, tf.float32)\n",
    "\n",
    "      dropprob = tf.placeholder_with_default(0.5, shape=(),name='prob')\n",
    "\n",
    "      # Distinguish training and testing: training=1 for training , =0 for testing\n",
    "      training = tf.placeholder_with_default(0.0, shape=(),name='training')\n",
    "      \n",
    "   \n",
    "    with tf.device('/gpu:0'):\n",
    "      \n",
    "      conv_filt_shape = [filter_shape, num_input_channels, num_filters]\n",
    "\n",
    "      stdConv=save_SigmaConv\n",
    "      # initialise weights and bias for the filter\n",
    "      conv_weights = tf.Variable(tf.truncated_normal(conv_filt_shape, mean=0,stddev=stdConv), name='Conv1_W')\n",
    "      conv_bias = tf.Variable(tf.truncated_normal([num_filters]), name='Conv1_b')\n",
    "\n",
    "\n",
    "\n",
    "      if pooling=='max_pool':\n",
    "          W = tf.Variable(tf.truncated_normal([16,32], mean=0, stddev=0.3), name='W')\n",
    "          b = tf.Variable(tf.truncated_normal([32], mean=0, stddev=0.3), name='b')\n",
    "      else:\n",
    "          W = tf.Variable(tf.truncated_normal([32,32], mean=0, stddev=0.3), name='W')\n",
    "          b = tf.Variable(tf.truncated_normal([32], mean=0, stddev=0.3), name='b')     \n",
    "\n",
    "      if neuType == 'nohidden':\n",
    "          if pooling=='max_pool':\n",
    "              wdim1=16\n",
    "          else:\n",
    "              wdim1=32\n",
    "      else:\n",
    "          wdim1=32\n",
    "      stdNeu=save_SigmaNeu\n",
    "      wd1 = tf.Variable(tf.truncated_normal([wdim1,1], mean=0, stddev=stdNeu), name='w2')\n",
    "      bd1 = tf.Variable(tf.truncated_normal([1], mean=0, stddev=stdNeu), name='b2')\n",
    "\n",
    "\n",
    "      xconv = convolution(data_X,num_input_channels,num_filters,filter_shape,conv_weights,conv_bias,wd1,bd1,W,b,pooling,neuType,training,dropprob)\n",
    "\n",
    "      sig = tf.nn.sigmoid(xconv)\n",
    "      if neuType == 'hidden':\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=data_y,logits=xconv))+ beta1*tf.norm(conv_weights,ord=1)+ beta2*tf.norm(wd1,ord=1)+ beta3*tf.norm(W,ord=1)\n",
    "      else:\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=data_y,logits=xconv))+ beta1*tf.norm(conv_weights,ord=1)+ beta2*tf.norm(wd1,ord=1)\n",
    "\n",
    "      optimizer=tf.train.MomentumOptimizer(learning_rate,momentum_rate,use_nesterov=True).minimize(loss)\n",
    "    with tf.device('/cpu:0'):\n",
    "      \n",
    "      #Set up iterator for the validation data\n",
    "      dataset_val = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "      dataset_val = dataset_val.batch(tf.cast(tf.size(y),tf.int64))\n",
    "                  \n",
    "      iterator_val = dataset_val.make_initializable_iterator()\n",
    "      data_XV, data_yV = iterator_val.get_next()      \n",
    "      data_yV = tf.cast(data_yV, tf.float32)\n",
    "      \n",
    "      \n",
    "      data_XV = tf.placeholder_with_default(data_XV, shape=None, name='input')\n",
    "      data_yV = tf.placeholder_with_default(data_yV, shape=None,name='label')\n",
    "      \n",
    "      \n",
    "    with tf.device('/gpu:0'):\n",
    "      xconvV = convolution(data_XV,num_input_channels,num_filters,filter_shape,conv_weights,conv_bias,wd1,bd1,W,b,pooling,neuType,training,dropprob)\n",
    "\n",
    "      sigV = tf.nn.sigmoid(xconvV, name='Conv_V')\n",
    "  \n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T13:39:41.900695Z",
     "start_time": "2021-06-01T13:38:25.515580Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "huj8k7YtXGXu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1070, pci bus id: 0000:09:00.0, compute capability: 6.1\n",
      "\n",
      "AUC of Model Num 0  is :  0.8999826904851369\n",
      "Best AUC So Far is :  0.8999826904851369\n",
      "Model Saved!\n",
      "AUC of Model Num 1  is :  0.8356876504620101\n",
      "AUC of Model Num 2  is :  0.9077662074938051\n",
      "Best AUC So Far is :  0.9077662074938051\n",
      "Model Saved!\n",
      "AUC of Model Num 3  is :  0.905445324217969\n",
      "AUC of Model Num 4  is :  0.8674421566618652\n",
      "AUC of Model Num 5  is :  0.9040580675803078\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session(graph=graph2, config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    auc_list=[]\n",
    "    best_auc=0\n",
    "    for iter in range(6):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        \n",
    "\n",
    "        prob=save_Dropprob\n",
    "        iterationSteps=0\n",
    "        sess.run(iterator.initializer, feed_dict = {x: data_all, y: label_all})\n",
    "        try:\n",
    "\n",
    "            while iterationSteps <=save_LearningStep:\n",
    "                  iterationSteps+=1\n",
    "              \n",
    "                  ### Training\n",
    "                  _,lss=sess.run([optimizer,loss], feed_dict= {training: 1, dropprob: prob})\n",
    "                  \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "          \n",
    "        ## Validation\n",
    "        sess.run(iterator_val.initializer, feed_dict = {x: data_all, y: label_all})\n",
    "        l,yl=sess.run([sigV,data_yV], feed_dict= {training: 0, dropprob: prob})\n",
    "\n",
    "        auc=metrics.roc_auc_score(yl, l)\n",
    "        print('AUC of Model Num',iter,' is : ', auc)\n",
    "        \n",
    "        if auc > best_auc:\n",
    "          best_auc=auc\n",
    "          print('Best AUC So Far is : ', best_auc)\n",
    "          ##save model\n",
    "          save_path = saver.save(sess, \"/home/julian/Documents/bat/DeepBind_with_Tensorflow/models\")\n",
    "          print('Model Saved!')\n",
    "\n",
    "          \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T13:42:35.827373Z",
     "start_time": "2021-06-01T13:42:35.825661Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "P4ES6bgYBbKh"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:07:50.185544Z",
     "start_time": "2021-06-01T14:07:50.183780Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8vr5DH5ER0k2"
   },
   "outputs": [],
   "source": [
    "filename='/home/julian/Documents/bat/DeepBind_train/data/encode/ELK1_GM12878_ELK1_(1277-1)_Stanford_B.seq.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:10:44.201631Z",
     "start_time": "2021-06-01T14:10:44.198619Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "5cRQzE9-YsAd"
   },
   "outputs": [],
   "source": [
    "class ChipTest(Experiment):\n",
    "    def __init__(self,filename,motiflen=24):\n",
    "        self.file = filename\n",
    "        self.motiflen = motiflen\n",
    "            \n",
    "    def openFile(self):\n",
    "        train_dataset=[]\n",
    "     \n",
    "        with gzip.open(self.file, 'rt') as data:\n",
    "            next(data)\n",
    "            reader = csv.reader(data,delimiter='\\t')\n",
    "            \n",
    "            for row in reader:\n",
    "                    train_dataset.append([seqtopad(row[2],self.motiflen),[row[3]]])\n",
    "                    \n",
    "                   \n",
    "        \n",
    "\n",
    "        return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:13:38.405102Z",
     "start_time": "2021-06-01T14:13:37.718882Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WbQxI6v4R2cb"
   },
   "outputs": [],
   "source": [
    "test= ChipTest(filename)\n",
    "dataAll =test.openFile()\n",
    "data_all=np.asarray([el[0] for el in dataAll],dtype=np.float32)\n",
    "label_all=np.asarray([el[1] for el in dataAll],dtype=np.float32).reshape(len(data_all),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T13:51:16.706042Z",
     "start_time": "2021-06-01T13:41:54.333Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "zO0bp4gHxTWw"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "TestGraph=tf.Graph()\n",
    "with tf.Session(graph=TestGraph) as sess:    \n",
    "  \n",
    "  # #First let's load meta graph and restore weights\n",
    "  ckpt = tf.train.get_checkpoint_state('/content/drive/My Drive/Colab Notebooks/Test2', latest_filename='checkpoint')\n",
    "  \n",
    "  if ckpt and ckpt.model_checkpoint_path:  # if there's checkpoint\n",
    "    saver = tf.train.import_meta_graph('/content/drive/My Drive/Colab Notebooks/Test2/model2.meta')\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "\n",
    "    X = TestGraph.get_tensor_by_name(\"input:0\")\n",
    "    y = TestGraph.get_tensor_by_name(\"label:0\")\n",
    "\n",
    "\n",
    "    training = TestGraph.get_tensor_by_name(\"training:0\")\n",
    "    prob = TestGraph.get_tensor_by_name(\"prob:0\")\n",
    "\n",
    "    # #Now, access the op to run. \n",
    "    Conv_V = TestGraph.get_tensor_by_name(\"Conv_V:0\")\n",
    "    feed_dict2={X:data_all,y:label_all,prob:save_Dropprob}\n",
    "    l=sess.run(Conv_V,feed_dict2)\n",
    "    auc=metrics.roc_auc_score(label_all, l)\n",
    "    print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-FVFwdZoNwxS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Deepbind.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
